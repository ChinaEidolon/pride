{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: numpy in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (1.23.1)\n",
      "Collecting Agent\n",
      "  Downloading agent-0.1.2.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: Agent\n",
      "  Building wheel for Agent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Agent: filename=agent-0.1.2-py3-none-any.whl size=4465 sha256=5164e85009e17664647d58633c1616fcbe9de40fa5a19e7355485656ec0989ec\n",
      "  Stored in directory: /Users/boqiang.liang/Library/Caches/pip/wheels/3f/5c/3f/4a0470d6701eb2b911dd9f7e96f0553cb980ae8e0f82dd706b\n",
      "Successfully built Agent\n",
      "Installing collected packages: Agent\n",
      "Successfully installed Agent-0.1.2\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement NonStructured_Encoder (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for NonStructured_Encoder\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting utils\n",
      "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: utils\n",
      "  Building wheel for utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13928 sha256=af1f30b34cc39a17e2214d5b375a93533aadf38d52a45a3797b0d5e92c5fded4\n",
      "  Stored in directory: /Users/boqiang.liang/Library/Caches/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
      "Successfully built utils\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mcopy\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mAgent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNonStructured_Encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NonStructured_Encoder\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_buffer, init_grad\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Agent'"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install tensorflow\n",
    "! python3 -m pip install numpy\n",
    "! python3 -m pip install NonStructured_Encoder\n",
    "! python3 -m pip install utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random, copy, math\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Agent in /Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages (0.1.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement NonStructured_Encoder (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for NonStructured_Encoder\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'agent' from 'agent' (/Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages/agent.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m python3 -m pip install Agent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m python3 -m pip install NonStructured_Encoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m agent\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNonStructured_Encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NonStructured_Encoder\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m update_buffer, init_grad\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'agent' from 'agent' (/Users/boqiang.liang/.pyenv/versions/3.10.4/lib/python3.10/site-packages/agent.py)"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install Agent\n",
    "! python3 -m pip install NonStructured_Encoder\n",
    "\n",
    "from agent import agent\n",
    "from NonStructured_Encoder import NonStructured_Encoder\n",
    "from utils import update_buffer, init_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire model\n",
    "\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, sess, FLAGS, embed, data_train=None): # FLAGS means value must be integer.\n",
    "        self.sess = sess #sessions allow graphs to run. Graphs: https://www.youtube.com/watch?v=hCP1vGoCdYU\n",
    "            # graph: Basically, J(a,b,c) = 3(a+bc). graph simply just defines this equation,\n",
    "            # and the values of a,b, and c.\n",
    "            # session allows the \"graph\" to run a specific amount of times, or whatnot.\n",
    "        self.num_relations = FLAGS.num_relations\n",
    "            # idk.\n",
    "        self.num_units = FLAGS.num_units\n",
    "            #  \n",
    "        self.dim_embed_relation = FLAGS.dim_embed_relation\n",
    "            # wha\n",
    "        self.max_edu_dist = FLAGS.max_edu_dist\n",
    "        self.dim_feature_bi = FLAGS.dim_feature_bi\n",
    "        self.use_structured = FLAGS.use_structured\n",
    "        self.use_speaker_attn = FLAGS.use_speaker_attn\n",
    "        self.use_shared_encoders = FLAGS.use_shared_encoders\n",
    "        self.use_random_structured = FLAGS.use_random_structured\n",
    "\n",
    "            # these are all self defined parameters set using FLAGS\n",
    "            # FLAGS is just a way to define the arguments through the 'Flag' object it owns\n",
    "        \n",
    "        self.learning_rate = tf.Variable(\n",
    "            float(FLAGS.learning_rate), trainable=False, dtype=tf.float32)                                   \n",
    "        self.learning_rate_decay_op = self.learning_rate.assign(\n",
    "            self.learning_rate * FLAGS.learning_rate_decay)\n",
    "        # this adjusts the learning rate of the object, the decay of it\n",
    "                \n",
    "        self.agent_bi = Agent(sess, FLAGS, embed, scope=\"agent_bi\", is_multi=False)\n",
    "            # for things that only involve binary output\n",
    "        self.agent_multi = Agent(sess, FLAGS, embed, scope=\"agent_multi\", is_multi=True)\n",
    "            # for multi-output\n",
    "\n",
    "        self.params_all = []\n",
    "        self.params_all += self.agent_bi.params_policy_network\n",
    "        if self.use_structured:\n",
    "            self.params_all += self.agent_bi.s_encoder_attn.params\n",
    "            self.params_all += self.agent_bi.s_encoder_general.params\n",
    "        self.params_all += self.agent_bi.ns_encoder.params\n",
    "        self.params_all += self.agent_multi.params_policy_network\n",
    "        if self.use_structured:\n",
    "            self.params_all += self.agent_multi.s_encoder_attn.params\n",
    "            self.params_all += self.agent_multi.s_encoder_general.params\n",
    "        self.params_all += self.agent_multi.ns_encoder.params\n",
    "        \n",
    "\n",
    "        \n",
    "        self.grad_unclipped = [\n",
    "            tf.placeholder(tf.float32, param.shape)\n",
    "            for param in self.params_all\n",
    "        ]\n",
    "        self.grad_clipped = tf.clip_by_global_norm(self.grad_unclipped, 5.0)\n",
    "        \n",
    "    def initialize(self, vocab):\n",
    "        self.agent_bi.ns_encoder.initialize(vocab)\n",
    "        self.agent_multi.ns_encoder.initialize(vocab)\n",
    "            \n",
    "    def sample_action(self, policy):\n",
    "        action = []\n",
    "        for p in policy:\n",
    "            action.append(np.argmax(p))\n",
    "        return action\n",
    "\n",
    "    def new_hp_bp_buf(self):\n",
    "        buf = {\n",
    "            \"grad_bi\": [],\n",
    "            \"parent_bi\": [],\n",
    "            \"current_bi\": [],\n",
    "            \"grad_multi\": [],\n",
    "            \"parent_multi\": [],\n",
    "            \"current_multi\": [],\n",
    "            \"relation\": [],\n",
    "            \"idx_parent\": [],\n",
    "            \"idx_current\": []\n",
    "        }\n",
    "        return [copy.deepcopy(buf), copy.deepcopy(buf)]       \n",
    "        \n",
    "    def backpropagate_hp(self, batch, k, j):\n",
    "        if not self.use_structured: return\n",
    "        speaker_j = batch[k][\"edus\"][j][\"speaker\"]\n",
    "        \n",
    "        for l in range(self.cnt_speakers[k]):\n",
    "            if abs(np.sum(self.grad_hp_bi[self.sentence_idx[k][j]][l])) < 1e-9\\\n",
    "                and abs(np.sum(self.grad_hp_multi[self.sentence_idx[k][j]][l])) < 1e-9 : continue\n",
    "            attn = bool(l == speaker_j)              \n",
    "            if not self.use_speaker_attn:\n",
    "                attn = 0  \n",
    "            for _i in range(len(self.parents_hp[k][j])):\n",
    "                par = self.parents[k][j][_i]\n",
    "                self.hp_bp_buf[attn][\"grad_bi\"].append(np.array(self.grad_hp_bi[self.sentence_idx[k][j]][l]))\n",
    "                self.hp_bp_buf[attn][\"parent_bi\"].append(np.array(self.hp_bi[self.sentence_idx[k][par]][l]))\n",
    "                self.hp_bp_buf[attn][\"current_bi\"].append(self.hs_bi[self.sentence_idx[k][j]])\n",
    "                self.hp_bp_buf[attn][\"grad_multi\"].append(np.array(self.grad_hp_multi[self.sentence_idx[k][j]][l]))\n",
    "                self.hp_bp_buf[attn][\"parent_multi\"].append(np.array(self.hp_multi[self.sentence_idx[k][par]][l]))\n",
    "                self.hp_bp_buf[attn][\"current_multi\"].append(self.hs_multi[self.sentence_idx[k][j]])\n",
    "                self.hp_bp_buf[attn][\"relation\"].append(self.parents_relation_hp[k][j][_i])\n",
    "                self.hp_bp_buf[attn][\"idx_parent\"].append((self.sentence_idx[k][par], l))\n",
    "                self.hp_bp_buf[attn][\"idx_current\"].append(self.sentence_idx[k][j])\n",
    "\n",
    "            self.hp_bp_buf[attn][\"grad_bi\"].append(np.array(self.grad_hp_bi[self.sentence_idx[k][j]][l]))\n",
    "            self.hp_bp_buf[attn][\"parent_bi\"].append(self.zero)\n",
    "            self.hp_bp_buf[attn][\"current_bi\"].append(self.hs_bi[self.sentence_idx[k][j]])\n",
    "            self.hp_bp_buf[attn][\"grad_multi\"].append(np.array(self.grad_hp_multi[self.sentence_idx[k][j]][l]))\n",
    "            self.hp_bp_buf[attn][\"parent_multi\"].append(self.zero)\n",
    "            self.hp_bp_buf[attn][\"current_multi\"].append(self.hs_multi[self.sentence_idx[k][j]])\n",
    "            self.hp_bp_buf[attn][\"relation\"].append(self.num_relations)\n",
    "            self.hp_bp_buf[attn][\"idx_parent\"].append(None)\n",
    "            self.hp_bp_buf[attn][\"idx_current\"].append(self.sentence_idx[k][j])\n",
    "\n",
    "            self.grad_hp_bi[self.sentence_idx[k][j]][l] = np.zeros(self.num_units)            \n",
    "            self.grad_hp_multi[self.sentence_idx[k][j]][l] = np.zeros(self.num_units)            \n",
    "               \n",
    "    def update_gradients(self, g1, g2):\n",
    "        if g2 is None: return\n",
    "        if g1 is None:\n",
    "            return np.array(g2)\n",
    "        else:\n",
    "            for l in range(len(g1)):\n",
    "                g1[l] += g2[l]\n",
    "            return g1\n",
    "       \n",
    "    def get_sum(self, grad):\n",
    "        s = 0\n",
    "        for item in grad:\n",
    "            s += np.sum(item)\n",
    "        return s\n",
    "                \n",
    "    def backpropagate_hp_flush(self):\n",
    "        if not self.use_structured: return\n",
    "        o_feed, i_feed = [], {}\n",
    "        for attn in range(0, 2):\n",
    "            if len(self.hp_bp_buf[attn][\"idx_parent\"]) == 0: continue\n",
    "            def update_gradients_buffer(o_feed, i_feed, agent, name):\n",
    "                return update_buffer(\n",
    "                    o_feed, i_feed,\n",
    "                    (agent.s_encoder_attn if attn else agent.s_encoder_general).get_gradients(\n",
    "                        self.hp_bp_buf[attn][\"grad_%s\" % name],\n",
    "                        self.hp_bp_buf[attn][\"parent_%s\" % name],\n",
    "                        self.hp_bp_buf[attn][\"current_%s\" % name],\n",
    "                        self.hp_bp_buf[attn][\"relation\"],\n",
    "                        buffered=True\n",
    "                    )\n",
    "                )\n",
    "            o_feed, i_feed = update_gradients_buffer(o_feed, i_feed, self.agent_bi, \"bi\")\n",
    "            o_feed, i_feed = update_gradients_buffer(o_feed, i_feed, self.agent_multi, \"multi\")\n",
    "            \n",
    "        res = self.sess.run(o_feed, i_feed)\n",
    "        c = 0\n",
    "   \n",
    "        for attn in range(0, 2):\n",
    "            if len(self.hp_bp_buf[attn][\"idx_parent\"]) == 0: continue\n",
    "            def update_gradients(agent, grad_hp, grad_hs, g_structured, g_parent, g_current):\n",
    "                for k, idx in enumerate(self.hp_bp_buf[attn][\"idx_parent\"]):\n",
    "                    if idx is not None:\n",
    "                        grad_hp[idx[0]][idx[1]] += g_parent[k]\n",
    "                for k, idx in enumerate(self.hp_bp_buf[attn][\"idx_current\"]):\n",
    "                    grad_hs[idx] += g_current[k]\n",
    "                  \n",
    "                if attn:\n",
    "                    agent.grad_s_encoder_attn = self.update_gradients(agent.grad_s_encoder_attn, g_structured)\n",
    "                else:\n",
    "                    agent.grad_s_encoder_general = self.update_gradients(agent.grad_s_encoder_general, g_structured)\n",
    "            \n",
    "            update_gradients(\n",
    "                self.agent_bi, self.grad_hp_bi, self.grad_hs_bi, \n",
    "                res[c], res[c + 1][0], res[c + 1][1]\n",
    "            )\n",
    "            c += 2\n",
    "            update_gradients(\n",
    "                self.agent_multi, self.grad_hp_multi, self.grad_hs_multi, \n",
    "                res[c], res[c + 1][0], res[c + 1][1]\n",
    "            )   \n",
    "            c += 2\n",
    "                \n",
    "        self.hp_bp_buf = self.new_hp_bp_buf()        \n",
    "        \n",
    "    def backpropagate_hp_all(self, batch):\n",
    "        if self.use_structured:\n",
    "            # hp backpropagation\n",
    "            for k, dialog in enumerate(batch):\n",
    "                for j in range(len(dialog[\"edus\"]) - 1, -1, -1):\n",
    "                    self.backpropagate_hp(batch, k, j)\n",
    "            self.backpropagate_hp_flush()\n",
    "\n",
    "    def get_hs(self, batch):\n",
    "        self.max_num_edus = max([len(dialog[\"edus\"]) for dialog in batch])\n",
    "        self.edus, self.num_posts = [], []\n",
    "        for dialog in batch:\n",
    "            self.edus.append([])\n",
    "            for edu in dialog[\"edus\"]:\n",
    "                self.edus[-1].append(edu[\"tokens\"])\n",
    "            for i in range(self.max_num_edus - len(dialog[\"edus\"])):\n",
    "                self.edus[-1].append([])\n",
    "            self.num_posts.append(len(dialog[\"edus\"]))\n",
    "        \n",
    "        o_feed, i_feed = [], {}\n",
    "        o_feed, i_feed = update_buffer(\n",
    "            o_feed, i_feed, \n",
    "            self.agent_bi.ns_encoder.infer(self.edus, self.num_posts, is_train=self.is_train, buffered=True)\n",
    "        )\n",
    "        o_feed, i_feed = update_buffer(\n",
    "            o_feed, i_feed, \n",
    "            self.agent_multi.ns_encoder.infer(self.edus, self.num_posts, is_train=self.is_train, buffered=True)\n",
    "        )\n",
    "\n",
    "        res = self.sess.run(o_feed, i_feed)\n",
    "                \n",
    "        self.sentences = []\n",
    "        self.sentence_idx = []\n",
    "        for dialog in batch:\n",
    "            idx = []\n",
    "            for edu in dialog[\"edus\"]:\n",
    "                self.sentences.append(edu[\"tokens\"])\n",
    "                idx.append(len(self.sentences) - 1)\n",
    "            self.sentence_idx.append(idx)\n",
    "            \n",
    "        self.hs_bi, self.hs_multi, self.hs_idp, self.hc_bi, self.hc_multi = [], [], [], [], []\n",
    "        for i, dialog in enumerate(batch):\n",
    "            for j in range(len(dialog[\"edus\"])):\n",
    "                idx = i * self.max_num_edus + j\n",
    "                self.hs_bi.append(res[0][idx])\n",
    "                self.hs_multi.append(res[3][idx])\n",
    "                self.hc_bi.append(res[1][idx])\n",
    "                self.hc_multi.append(res[4][idx])\n",
    "        \n",
    "        self.agent_bi.ns_encoder.recurrent_noise = res[2]\n",
    "        self.agent_multi.ns_encoder.recurrent_noise = res[5]\n",
    "            \n",
    "        self.hs_bi = np.array(self.hs_bi)\n",
    "        self.hs_multi = np.array(self.hs_multi)\n",
    "        self.grad_hs_bi = np.zeros(self.hs_bi.shape)      \n",
    "        self.grad_hs_multi = np.zeros(self.hs_multi.shape)  \n",
    "        self.hc_bi = np.array(self.hc_bi)\n",
    "        self.hc_multi = np.array(self.hc_multi)\n",
    "        self.grad_hc_bi = np.zeros(self.hc_bi.shape)      \n",
    "        self.grad_hc_multi = np.zeros(self.hc_multi.shape)  \n",
    "    \n",
    "    def count_speakers(self, batch):\n",
    "        self.cnt_speakers = []\n",
    "        for i, dialog in enumerate(batch):\n",
    "            speakers = {}\n",
    "            for edu in dialog[\"edus\"]:\n",
    "                if not edu[\"speaker\"] in speakers:\n",
    "                    speakers[edu[\"speaker\"]] = len(speakers)\n",
    "                edu[\"speaker\"] = speakers[edu[\"speaker\"]]\n",
    "            self.cnt_speakers.append(len(speakers))\n",
    "            \n",
    "    def get_hp_new_buf(self):\n",
    "        buf = {\n",
    "            \"parent_bi\": [],\n",
    "            \"current_bi\": [],\n",
    "            \"parent_multi\": [],\n",
    "            \"current_multi\": [],\n",
    "            \"relation\": [],\n",
    "            \"idx\": []\n",
    "        }\n",
    "        return [copy.deepcopy(buf), copy.deepcopy(buf)] \n",
    "            \n",
    "    def init_hp(self, batch):\n",
    "        # parent path representation\n",
    "        self.hp_bi = np.zeros((len(self.sentences), max(self.cnt_speakers), self.num_units))\n",
    "        self.hp_multi = np.zeros((len(self.sentences), max(self.cnt_speakers), self.num_units))\n",
    "        \n",
    "        self.cntp = np.ones(len(self.sentences))    \n",
    "        self.is_root = np.ones(len(self.sentences)) \n",
    "           \n",
    "        # root\n",
    "        self.hp_new_buf = self.get_hp_new_buf()\n",
    "        self.zero = np.zeros(self.num_units)\n",
    "        \n",
    "        for k, dialog in enumerate(batch):\n",
    "            for j in range(len(dialog[\"edus\"])):\n",
    "                idx_j = self.sentence_idx[k][j] \n",
    "                for l in range(self.cnt_speakers[k]):\n",
    "                    attn = bool(l == batch[k][\"edus\"][j][\"speaker\"])\n",
    "                    if not self.use_speaker_attn:\n",
    "                        attn = 0\n",
    "                    self.hp_new_buf[attn][\"parent_bi\"].append(self.zero)\n",
    "                    self.hp_new_buf[attn][\"current_bi\"].append(self.hs_bi[idx_j])\n",
    "                    self.hp_new_buf[attn][\"parent_multi\"].append(self.zero)\n",
    "                    self.hp_new_buf[attn][\"current_multi\"].append(self.hs_multi[idx_j])\n",
    "                    self.hp_new_buf[attn][\"relation\"].append(self.num_relations)\n",
    "                    self.hp_new_buf[attn][\"idx\"].append((idx_j, l)) \n",
    "        self.update_hp(batch, fixed_noise=0)\n",
    "        self.hp_bp_buf = self.new_hp_bp_buf()\n",
    "\n",
    "        self.grad_hp_bi = np.zeros(self.hp_bi.shape)\n",
    "        self.grad_hp_multi = np.zeros(self.hp_multi.shape)\n",
    "        \n",
    "    def build_relation_list(self, batch):\n",
    "        # relation list\n",
    "        cnt_golden = 0\n",
    "        self.relation_list = []\n",
    "        self.relation_types = []\n",
    "        self.parents = []\n",
    "        self.parents_relation = []\n",
    "        self.parents_hp = []\n",
    "        self.parents_relation_hp = []\n",
    "        for k, dialog in enumerate(batch):\n",
    "            self.parents.append([[] for i in range(len(dialog[\"edus\"]))])\n",
    "            self.parents_relation.append([[] for i in range(len(dialog[\"edus\"]))])\n",
    "            self.parents_hp.append([[] for i in range(len(dialog[\"edus\"]))])\n",
    "            self.parents_relation_hp.append([[] for i in range(len(dialog[\"edus\"]))])\n",
    "            self.relation_types.append(np.zeros((len(dialog[\"edus\"]), len(dialog[\"edus\"])), dtype=np.int32))\n",
    "            for relation in dialog[\"relations\"]:\n",
    "                self.relation_types[k][relation[\"x\"]][relation[\"y\"]] = relation[\"type\"] + 1\n",
    "                cnt_golden += 1\n",
    "            for j in range(len(dialog[\"edus\"])):\n",
    "                r = []\n",
    "                for i in range(len(dialog[\"edus\"])):\n",
    "                    if self.relation_types[k][i][j] > 0 and \\\n",
    "                        (i < j and j - i <= self.max_edu_dist):\n",
    "                            r.append(i)\n",
    "                self.relation_list.append(r)        \n",
    "        return cnt_golden\n",
    "        \n",
    "    def get_state(self, batch, hs, hc, hp, k, i, j):\n",
    "        idx_i = self.sentence_idx[k][i]\n",
    "        idx_j = self.sentence_idx[k][j]\n",
    "        speaker_i = batch[k][\"edus\"][i][\"speaker\"]\n",
    "        speaker_j = batch[k][\"edus\"][j][\"speaker\"]\n",
    "        \n",
    "        h = np.concatenate([\n",
    "            hc[idx_i],\n",
    "            hs[idx_j],\n",
    "        ], axis=-1)      \n",
    "        if self.use_structured:\n",
    "            h = np.concatenate([\n",
    "                h,\n",
    "                hp[idx_i][speaker_j],\n",
    "                hc[idx_j],\n",
    "            ], axis=-1)\n",
    "        else:\n",
    "            h = np.concatenate([\n",
    "                h,\n",
    "                hs[idx_i],\n",
    "                hc[idx_j],\n",
    "            ], axis=-1)\n",
    "            \n",
    "        h = np.concatenate([\n",
    "            h,\n",
    "            [\n",
    "                j - i, \n",
    "                speaker_i == speaker_j,\n",
    "                batch[k][\"edus\"][i][\"turn\"] == batch[k][\"edus\"][j][\"turn\"],\n",
    "                (i in self.parents[k][j]) or (j in self.parents[k][i])\n",
    "            ]\n",
    "        ], axis=-1)\n",
    "            \n",
    "        return h\n",
    "        \n",
    "    def update_grad_state(self, batch, grad_hs, grad_hc, grad_hp, g_state, k, i, j):\n",
    "        idx_i = self.sentence_idx[k][i]\n",
    "        idx_j = self.sentence_idx[k][j]\n",
    "        speaker_i = batch[k][\"edus\"][i][\"speaker\"]\n",
    "        speaker_j = batch[k][\"edus\"][j][\"speaker\"]   \n",
    "        \n",
    "        grad_hc[idx_i] += g_state[0:self.num_units]\n",
    "        grad_hs[idx_j] += g_state[self.num_units:2*self.num_units]\n",
    "        if self.use_structured:\n",
    "            grad_hp[idx_i][speaker_j] += g_state[2*self.num_units:3*self.num_units]\n",
    "            grad_hc[idx_j] += g_state[3*self.num_units:4*self.num_units]\n",
    "        else:\n",
    "            grad_hs[idx_i] += g_state[2*self.num_units:3*self.num_units]\n",
    "            grad_hc[idx_j] += g_state[3*self.num_units:4*self.num_units]         \n",
    "            \n",
    "    def new_edge(self, batch, k, i, j, r):\n",
    "        # bp gradients of hp first before a new parent is added\n",
    "        if self.use_structured:\n",
    "            self.backpropagate_hp(batch, k, j)\n",
    "        \n",
    "        self.parents[k][j].append(i)\n",
    "        self.parents_relation[k][j].append(r)\n",
    "        \n",
    "        if self.use_random_structured:\n",
    "            i = random.randint(0, j - 1)\n",
    "            r = random.randint(0, self.num_relations - 1)\n",
    "        \n",
    "        self.parents_hp[k][j].append(i)\n",
    "        self.parents_relation_hp[k][j].append(r)\n",
    "        \n",
    "        idx_j = self.sentence_idx[k][j]\n",
    "        if self.use_structured:\n",
    "            if self.is_root[idx_j]:\n",
    "                self.is_root[idx_j] = 0\n",
    "                self.cntp[idx_j] = 1\n",
    "            else:\n",
    "                self.cntp[idx_j] += 1\n",
    "                \n",
    "            for l in range(self.cnt_speakers[k]):\n",
    "                attn = bool(l == batch[k][\"edus\"][j][\"speaker\"])\n",
    "                if not self.use_speaker_attn:\n",
    "                    attn = 0\n",
    "                self.hp_new_buf[attn][\"parent_bi\"].append(np.array(self.hp_bi[self.sentence_idx[k][i]][l]))\n",
    "                self.hp_new_buf[attn][\"current_bi\"].append(self.hs_bi[idx_j])\n",
    "                self.hp_new_buf[attn][\"parent_multi\"].append(np.array(self.hp_multi[self.sentence_idx[k][i]][l]))\n",
    "                self.hp_new_buf[attn][\"current_multi\"].append(self.hs_multi[idx_j])\n",
    "                self.hp_new_buf[attn][\"relation\"].append(r)\n",
    "                self.hp_new_buf[attn][\"idx\"].append((idx_j, l))   \n",
    "           \n",
    "    def update_hp(self, batch, fixed_noise=1):    \n",
    "        o_feed, i_feed = [], {}\n",
    "        \n",
    "        for attn in range(0, 2):\n",
    "            if len(self.hp_new_buf[attn][\"idx\"]) == 0: continue\n",
    "            def update_hp_buffer(o_feed, i_feed, agent, name, hp):\n",
    "                self.hp_new_buf[attn][\"parent\"] = np.array(self.hp_new_buf[attn][\"parent_%s\" % name])\n",
    "                self.hp_new_buf[attn][\"current\"] = np.array(self.hp_new_buf[attn][\"current_%s\" % name])\n",
    "                self.hp_new_buf[attn][\"relation\"] = np.array(self.hp_new_buf[attn][\"relation\"])\n",
    "                return update_buffer(\n",
    "                    o_feed, i_feed,\n",
    "                    (agent.s_encoder_attn if attn else agent.s_encoder_general)\\\n",
    "                        .infer(self.hp_new_buf[attn], fixed_noise, buffered=True)\n",
    "                )\n",
    "            o_feed, i_feed = update_hp_buffer(o_feed, i_feed, self.agent_bi, \"bi\", self.hp_bi)\n",
    "            o_feed, i_feed = update_hp_buffer(o_feed, i_feed, self.agent_multi, \"multi\", self.hp_multi)\n",
    "                \n",
    "        res = self.sess.run(o_feed, i_feed)\n",
    "        c = 0\n",
    "        \n",
    "        for attn in range(0, 2):\n",
    "            if len(self.hp_new_buf[attn][\"idx\"]) == 0: continue\n",
    "            def update_hp(hp, _hp):\n",
    "                for i, idx in enumerate(self.hp_new_buf[attn][\"idx\"]):\n",
    "                    if self.cntp[idx[0]] == 1:\n",
    "                        hp[idx[0]][idx[1]] = _hp[i]\n",
    "                    else:\n",
    "                        hp[idx[0]][idx[1]] += _hp[i]\n",
    "            update_hp(self.hp_bi, res[c])\n",
    "            if attn:\n",
    "                self.agent_bi.s_encoder_attn.recurrent_noise = res[c + 1]\n",
    "            else:\n",
    "                self.agent_bi.s_encoder_general.recurrent_noise = res[c + 1]\n",
    "            c += 2\n",
    "\n",
    "            update_hp(self.hp_multi, res[c])\n",
    "            if attn:\n",
    "                self.agent_multi.s_encoder_attn.recurrent_noise = res[c + 1]\n",
    "            else:\n",
    "                self.agent_multi.s_encoder_general.recurrent_noise = res[c + 1]\n",
    "            c += 2\n",
    "         \n",
    "    def clip_gradients(self):\n",
    "        gradients = []\n",
    "        def append_grad(grad):            \n",
    "            return gradients + list(grad)\n",
    "        gradients = append_grad(self.agent_bi.grad_policy)\n",
    "        if self.use_structured:\n",
    "            gradients = append_grad(self.agent_bi.grad_s_encoder_attn)\n",
    "            gradients = append_grad(self.agent_bi.grad_s_encoder_general)\n",
    "        gradients = append_grad(self.agent_bi.grad_ns_encoder)\n",
    "        gradients = append_grad(self.agent_multi.grad_policy)\n",
    "        if self.use_structured:\n",
    "            gradients = append_grad(self.agent_multi.grad_s_encoder_attn)\n",
    "            gradients = append_grad(self.agent_multi.grad_s_encoder_general)\n",
    "        gradients = append_grad(self.agent_multi.grad_ns_encoder)\n",
    "        \n",
    "        input_feed = {}\n",
    "        for i in range(len(gradients)):\n",
    "            input_feed[self.grad_unclipped[i]] = gradients[i]\n",
    "        gradients_clipped, global_norm = self.sess.run(\n",
    "            self.grad_clipped, input_feed)\n",
    "            \n",
    "        def get_clipped(grad):\n",
    "            return gradients_clipped[:len(grad)], gradients_clipped[len(grad):]\n",
    "            \n",
    "        self.agent_bi.grad_policy, gradients_clipped = get_clipped(self.agent_bi.grad_policy)\n",
    "        if self.use_structured:\n",
    "            self.agent_bi.grad_s_encoder_attn, gradients_clipped = get_clipped(self.agent_bi.grad_s_encoder_attn)\n",
    "            self.agent_bi.grad_s_encoder_general, gradients_clipped = get_clipped(self.agent_bi.grad_s_encoder_general)\n",
    "        self.agent_bi.grad_ns_encoder, gradients_clipped = get_clipped(self.agent_bi.grad_ns_encoder)\n",
    "        self.agent_multi.grad_policy, gradients_clipped = get_clipped(self.agent_multi.grad_policy)\n",
    "        if self.use_structured:\n",
    "            self.agent_multi.grad_s_encoder_attn, gradients_clipped = get_clipped(self.agent_multi.grad_s_encoder_attn)\n",
    "            self.agent_multi.grad_s_encoder_general, gradients_clipped = get_clipped(self.agent_multi.grad_s_encoder_general)\n",
    "        self.agent_multi.grad_ns_encoder, gradients_clipped = get_clipped(self.agent_multi.grad_ns_encoder)\n",
    "         \n",
    "    def train(self, batch):\n",
    "        grad_hs_bi = np.zeros((len(batch) * self.max_num_edus, self.hs_bi.shape[1]))\n",
    "        grad_hc_bi = np.zeros((len(batch) * self.max_num_edus, self.hc_bi.shape[1]))\n",
    "        grad_hs_multi = np.zeros((len(batch) * self.max_num_edus, self.hs_multi.shape[1]))\n",
    "        grad_hc_multi = np.zeros((len(batch) * self.max_num_edus, self.hc_multi.shape[1]))\n",
    "        \n",
    "        cur = 0\n",
    "        for i, dialog in enumerate(batch):\n",
    "            grad_hs_bi[i * self.max_num_edus: i * self.max_num_edus + len(dialog[\"edus\"]), :] = \\\n",
    "                self.grad_hs_bi[cur : cur + len(dialog[\"edus\"]), :]\n",
    "            grad_hs_multi[i * self.max_num_edus: i * self.max_num_edus + len(dialog[\"edus\"]), :] = \\\n",
    "                self.grad_hs_multi[cur : cur + len(dialog[\"edus\"]), :]\n",
    "            grad_hc_bi[i * self.max_num_edus: i * self.max_num_edus + len(dialog[\"edus\"]), :] = \\\n",
    "                self.grad_hc_bi[cur : cur + len(dialog[\"edus\"]), :]\n",
    "            grad_hc_multi[i * self.max_num_edus: i * self.max_num_edus + len(dialog[\"edus\"]), :] = \\\n",
    "                self.grad_hc_multi[cur : cur + len(dialog[\"edus\"]), :]\n",
    "            cur += len(dialog[\"edus\"])\n",
    "        \n",
    "        o_feed, i_feed = self.agent_bi.ns_encoder\\\n",
    "            .get_gradients(self.edus, self.num_posts, grad_hs_bi, grad_hc_bi, buffered=True)\n",
    "        o_feed, i_feed = update_buffer(\n",
    "            o_feed, i_feed, \n",
    "            self.agent_multi.ns_encoder.get_gradients(\n",
    "                self.edus, self.num_posts, grad_hs_multi, grad_hc_multi, buffered=True)\n",
    "        )\n",
    "        res = self.sess.run(o_feed, i_feed)\n",
    "        self.agent_bi.grad_ns_encoder = res[0]\n",
    "        self.agent_multi.grad_ns_encoder = res[1]\n",
    "            \n",
    "        self.clip_gradients()\n",
    "                    \n",
    "        output_feed, input_feed = self.agent_bi.train(self.learning_rate.eval(), buffered=True)\n",
    "        output_feed, input_feed = update_buffer(\n",
    "            output_feed, input_feed, \n",
    "            self.agent_multi.train(self.learning_rate.eval(), buffered=True)\n",
    "        )\n",
    "        \n",
    "        self.sess.run(output_feed, input_feed)        \n",
    "                \n",
    "    def step(self, batch, is_train=False):\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        self.agent_bi.clear_gradients()\n",
    "        self.agent_multi.clear_gradients()\n",
    "        \n",
    "        cnt_golden, cnt_pred, cnt_cor_bi, cnt_cor_multi = 0, 0, 0, 0\n",
    "        sum_loss_bi, cnt_loss_bi = 0, 0\n",
    "        sum_loss_multi, cnt_loss_multi = 0, 0\n",
    "        \n",
    "        self.get_hs(batch)\n",
    "        self.count_speakers(batch)\n",
    "        if self.use_structured: \n",
    "            self.init_hp(batch)\n",
    "        else:\n",
    "            self.hp_bi, self.hp_multi = None, None\n",
    "            self.grad_hp_bi, self.grad_hp_multi = None, None\n",
    "        cnt_golden = self.build_relation_list(batch)\n",
    "        \n",
    "        cur = [(1, 0)] * len(batch)\n",
    "        unfinished = np.ones(len(batch), dtype=np.int32)\n",
    "        max_edus = max([len(dialog[\"edus\"]) for dialog in batch])\n",
    "        for k, dialog in enumerate(batch):\n",
    "            if len(dialog[\"edus\"]) <= 1:\n",
    "                unfinished[k] = False\n",
    "        \n",
    "        while (np.sum(unfinished) > 0):\n",
    "            size = np.sum(unfinished)\n",
    "            state = np.zeros((size, max_edus + 1, self.agent_bi.dim_state))\n",
    "            state_multi = np.zeros((size, max_edus + 1, self.agent_multi.dim_state))\n",
    "            mask = np.zeros((size, max_edus + 1))\n",
    "            golden = np.zeros(size, dtype=np.int32)\n",
    "            idx = 0\n",
    "            \n",
    "            for k, dialog in enumerate(batch):\n",
    "                if not unfinished[k]: continue\n",
    "                j = cur[k][0]\n",
    "                idx_j = self.sentence_idx[k][j]\n",
    "                for i in range(j):\n",
    "                    if j - i <= self.max_edu_dist:\n",
    "                        if (i in self.parents[k][j]): continue\n",
    "                        idx_i = self.sentence_idx[k][i]\n",
    "                        state[idx][i] = self.get_state(\n",
    "                            batch, \n",
    "                            self.hs_bi,\n",
    "                            self.hc_bi,\n",
    "                            self.hp_bi, \n",
    "                            k, i, j\n",
    "                        )\n",
    "                        state_multi[idx][i] = self.get_state(\n",
    "                            batch, \n",
    "                            self.hs_multi,\n",
    "                            self.hc_multi,\n",
    "                            self.hp_multi, \n",
    "                            k, i, j\n",
    "                        )                        \n",
    "                        mask[idx][i] = 1\n",
    "                    \n",
    "                golden[idx] = 0\n",
    "                for i in self.relation_list[idx_j]:\n",
    "                    if (i in self.parents[k][j]): continue\n",
    "                    golden[idx] = i\n",
    "                    break\n",
    "                idx += 1\n",
    "                \n",
    "            # sample an action\n",
    "            policy = self.agent_bi.get_policy(state, mask)\n",
    "                \n",
    "            action = self.sample_action(policy)\n",
    "            if not action:\n",
    "                print policy\n",
    "                raise Warning(\"Action not found, policy:\")\n",
    "                \n",
    "            # update prec/recall statistics\n",
    "            idx = 0\n",
    "            for k, dialog in enumerate(batch):\n",
    "                if not unfinished[k]: continue\n",
    "                # predicted a new relation\n",
    "                if action[idx] != len(dialog[\"edus\"]):\n",
    "                    cnt_pred += 1\n",
    "                    if self.relation_types[k][action[idx]][cur[k][0]] > 0:\n",
    "                        cnt_cor_bi += 1\n",
    "                idx += 1\n",
    "                \n",
    "            if is_train:\n",
    "                # use MLE loss (bi)\n",
    "                loss, g_policy, g_state = self.agent_bi.get_gradients(state, golden, mask)                \n",
    "                \n",
    "                # accumulate gradient for policy network\n",
    "                self.agent_bi.grad_policy = self.update_gradients(\n",
    "                    self.agent_bi.grad_policy, g_policy)\n",
    "                     \n",
    "                # accumulate gradient for hs and hp\n",
    "                idx = 0\n",
    "                for k, dialog in enumerate(batch):\n",
    "                    if not unfinished[k]: continue                    \n",
    "                    j = cur[k][0]\n",
    "                    idx_j = self.sentence_idx[k][j]\n",
    "                    speaker_j = dialog[\"edus\"][j][\"speaker\"]\n",
    "                    for i in range(len(dialog[\"edus\"])):\n",
    "                        if mask[idx][i] > 0:\n",
    "                            self.update_grad_state(\n",
    "                                batch, self.grad_hs_bi, self.grad_hc_bi, self.grad_hp_bi, g_state[idx, i, :], k, i, j) \n",
    "                    idx += 1\n",
    "                        \n",
    "                sum_loss_bi += loss\n",
    "                cnt_loss_bi += 1\n",
    "                    \n",
    "            # predict labels        \n",
    "            idx = 0\n",
    "            state_multi, golden_multi, idx_multi = [], [], []\n",
    "            state_multi_train, golden_multi_train, idx_multi_train = [], [], []\n",
    "            for k, dialog in enumerate(batch):\n",
    "                if not unfinished[k]: continue\n",
    "                j = cur[k][0]\n",
    "                if action[idx] != len(dialog[\"edus\"]):\n",
    "                    i = action[idx]\n",
    "                    if self.use_shared_encoders:\n",
    "                        state_multi.append(self.get_state(\n",
    "                            batch, \n",
    "                            self.hs_bi,\n",
    "                            self.hc_bi,\n",
    "                            self.hp_bi, \n",
    "                            k, i, j\n",
    "                        ))\n",
    "                    else:\n",
    "                        state_multi.append(self.get_state(\n",
    "                            batch, \n",
    "                            self.hs_multi,\n",
    "                            self.hc_multi,\n",
    "                            self.hp_multi, \n",
    "                            k, i, j\n",
    "                        ))\n",
    "                    idx_multi.append((k, i, j))   \n",
    "                for i in range(j):\n",
    "                    if self.relation_types[k][i][j] > 0:\n",
    "                        if i in self.parents[k][j]: continue\n",
    "                        if self.use_shared_encoders:\n",
    "                            state_multi_train.append(self.get_state(\n",
    "                                batch, \n",
    "                                self.hs_bi,\n",
    "                                self.hc_bi,\n",
    "                                self.hp_bi, \n",
    "                                k, i, j)\n",
    "                            )\n",
    "                        else:\n",
    "                            state_multi_train.append(self.get_state(\n",
    "                                batch, \n",
    "                                self.hs_multi,\n",
    "                                self.hc_multi,\n",
    "                                self.hp_multi, \n",
    "                                k, i, j)\n",
    "                            )\n",
    "                        idx_multi_train.append((k, i, j))\n",
    "                        golden_multi_train.append(self.relation_types[k][i][j] - 1)\n",
    "                idx += 1\n",
    "            if len(idx_multi) > 0:\n",
    "                policy = self.agent_multi.get_policy(state_multi)\n",
    "                labels = self.sample_action(policy)\n",
    "                \n",
    "            # use MLE loss (multi)\n",
    "            if len(idx_multi_train) > 0:\n",
    "                loss, g_policy, g_state = self.agent_multi.get_gradients(state_multi_train, golden_multi_train)\n",
    "                \n",
    "                if is_train:\n",
    "                    # accumulate gradient for policy network\n",
    "                    self.agent_multi.grad_policy = self.update_gradients(\n",
    "                        self.agent_multi.grad_policy, g_policy)\n",
    "                         \n",
    "                    # accumulate gradient for self.hs and self.hp\n",
    "                    for l, idx in enumerate(idx_multi_train):\n",
    "                        k, i, j = idx[0], idx[1], idx[2]\n",
    "                        if self.use_shared_encoders:\n",
    "                            self.update_grad_state(\n",
    "                                batch, self.grad_hs_bi, self.grad_hc_bi, self.grad_hp_bi, g_state[l, :], k, i, j)  \n",
    "                        else:\n",
    "                            self.update_grad_state(\n",
    "                                batch, self.grad_hs_multi, self.grad_hc_multi, self.grad_hp_multi, g_state[l, :], k, i, j)  \n",
    "                sum_loss_multi += loss\n",
    "                cnt_loss_multi += 1    \n",
    "                    \n",
    "            # update prec/recall statistics\n",
    "            idx, idx_multi = 0, 0\n",
    "            for k, dialog in enumerate(batch):\n",
    "                if not unfinished[k]: continue    \n",
    "                # predicted a new relation\n",
    "                if action[idx] != len(dialog[\"edus\"]):\n",
    "                    if labels[idx_multi] == self.relation_types[k][action[idx]][cur[k][0]] - 1:\n",
    "                        cnt_cor_multi += 1\n",
    "                    idx_multi += 1\n",
    "                idx += 1\n",
    "                  \n",
    "            # buffer for updating parent path representations   \n",
    "            self.hp_new_buf = self.get_hp_new_buf()\n",
    "                           \n",
    "            # take action   \n",
    "            if self.use_structured:\n",
    "                self.hp_bp_buf = self.new_hp_bp_buf()\n",
    "            idx, idx_multi, idx_multi_train = 0, 0, 0\n",
    "            for k, dialog in enumerate(batch):\n",
    "                if not unfinished[k]: continue\n",
    "                # valid prediction\n",
    "                if action[idx] != len(dialog[\"edus\"]):\n",
    "                    r = labels[idx_multi]\n",
    "                    if self.relation_types[k][action[idx]][cur[k][0]] > 0:\n",
    "                        idx_multi_train += 1\n",
    "                    idx_multi += 1\n",
    "                    self.new_edge(batch, k, action[idx], cur[k][0], r)\n",
    "                cur[k] = (cur[k][0] + 1, 0)\n",
    "                if cur[k][0] >= len(dialog[\"edus\"]):\n",
    "                    unfinished[k] = False                    \n",
    "                idx += 1\n",
    "            if self.use_structured:\n",
    "                self.backpropagate_hp_flush()\n",
    "                self.update_hp(batch)\n",
    "                    \n",
    "        # update the parameters        \n",
    "        if is_train:\n",
    "            self.backpropagate_hp_all(batch)\n",
    "            self.train(batch)\n",
    "                \n",
    "        relations_pred = []\n",
    "        for k, dialog in enumerate(batch):\n",
    "            relations_pred.append([])\n",
    "            for i in range(len(dialog[\"edus\"])):\n",
    "                for j in range(len(self.parents[k][i])):\n",
    "                    relations_pred[k].append((self.parents[k][i][j], i, self.parents_relation[k][i][j]))\n",
    "            \n",
    "        if is_train:\n",
    "            if math.isnan(sum_loss_bi) or math.isnan(sum_loss_multi):\n",
    "                print \"sum_loss_bi\", sum_loss_bi\n",
    "                print \"sum_loss_multi\", sum_loss_multi\n",
    "                raise Warning(\"NaN appears!\")\n",
    "        \n",
    "        for dialog in batch:\n",
    "            cnt = [0] * len(dialog[\"edus\"])\n",
    "            for r in dialog[\"relations\"]:\n",
    "                cnt[r[\"y\"]] += 1\n",
    "            for i in range(len(dialog[\"edus\"])):\n",
    "                if cnt[i] == 0:\n",
    "                    cnt_golden += 1\n",
    "            cnt_pred += 1\n",
    "            if cnt[0] == 0:\n",
    "                cnt_cor_bi += 1\n",
    "                cnt_cor_multi += 1\n",
    "            \n",
    "        return [\n",
    "            sum_loss_bi / cnt_loss_bi if cnt_loss_bi > 0 else 0, \n",
    "            sum_loss_multi / cnt_loss_multi if cnt_loss_multi > 0 else 0,\n",
    "            cnt_golden, cnt_pred, cnt_cor_bi, cnt_cor_multi,\n",
    "            relations_pred,\n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
